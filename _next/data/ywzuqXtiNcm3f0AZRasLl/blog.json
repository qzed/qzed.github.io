{"pageProps":{"posts":[{"slug":"20220825-irl-maxent","title":"Maximum Entropy Inverse Reinforcement Learning","author":"Maximilian Luz","date":1661385600000,"abstract":"var Component=(()=>{var p=Object.create;var a=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var v=(n,e)=>()=>(n&&(e=n(n=0)),e);var x=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),y=(n,e)=>{for(var i in e)a(n,i,{get:e[i],enumerable:!0})},m=(n,e,i,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let r of g(e))!u.call(n,r)&&r!==i&&a(n,r,{get:()=>e[r],enumerable:!(s=d(e,r))||s.enumerable});return n};var b=(n,e,i)=>(i=n!=null?p(f(n)):{},m(e||!n||!n.__esModule?a(i,\"default\",{value:n,enumerable:!0}):i,n)),w=n=>m(a({},\"__esModule\",{value:!0}),n);var o=v(()=>{});var l=x((C,c)=>{o();c.exports=_jsx_runtime});var L={};y(L,{default:()=>I});o();var t=b(l());function h(n){let e=Object.assign({p:\"p\",em:\"em\"},n.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.em,{children:\"Reinforcement learning (RL)\"}),` aims to provide a framework for finding the optimal behavior (i.e., an optimal policy) of intelligent agents regarding some environment they interact with by directing them via a reward signal, measuring their performance.\nWith the help of `,(0,t.jsx)(e.em,{children:\"inverse reinforcement learning (IRL)\"}),\" we can try to improve our agents by recovering the reward function (and therefore policy) of an expert, in essence using its domain knowledge for our needs.\"]}),`\n`,(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.em,{children:\"Maximum entropy IRL\"}),` is a comparatively simple but clever method of solving the general IRL problem for discrete Markov decision processes.\nIn this blog post, I will lay out the theoretical foundation of this approach, including the principle of maximum entropy, and derive the maximum entropy IRL algorithm.`]})]})}function _(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,Object.assign({},n,{children:(0,t.jsx)(h,n)})):h(n)}var I=_;return w(L);})();\n;return Component;","tags":["machine-learning","reinforcement-learning","inverse-reinforcement-learning"],"visibility":"default","content":null}]},"__N_SSG":true}